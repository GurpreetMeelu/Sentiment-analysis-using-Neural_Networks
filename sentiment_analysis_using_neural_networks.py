# -*- coding: utf-8 -*-
"""Sentiment Analysis Using Neural Networks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qwp4Y06eYF5EJ-n6JmEhnD4V0aVLlCyu

# **Classifying Movie Reviews**
Binary Classification on IMDB Dataset
"""

from keras.datasets import imdb

"""# Data Preprocessing"""

((XT,YT),(Xt,Yt)) = imdb.load_data(num_words=10000)

len(XT)

len(Xt)

word_idx = imdb.get_word_index()

print(word_idx.items())

idx_word = dict([value,key]  for (key,value) in word_idx.items())

print(idx_word.items())

#Vectorization of the data

import numpy as np

def vectorize_sentences(sentences, dim = 10000):
  outputs = np.zeros((len(sentences),dim))
  for i, idx in enumerate(sentences):
    outputs[i,idx] = 1
  return outputs

X_train = vectorize_sentences(XT)
X_test = vectorize_sentences(Xt)

print(X_train.shape)

Y_train = np.asarray(YT).astype('float32')
Y_test = np.asarray(Yt).astype('float32')

# Building a Network

from keras import models
from keras.layers import Dense

model = models.Sequential()
model.add(Dense(16, activation='relu',input_shape = (10000,)))
model.add(Dense(16,activation='relu'))
model.add(Dense(1,activation='sigmoid'))

model.compile(optimizer='rmsprop',loss = 'binary_crossentropy',metrics = ['accuracy'])

model.summary()

"""# Model Training"""

X_valid = X_train[:5000]
X_train_new = X_train[5000:]

Y_valid = Y_train[:5000]
Y_train_new = Y_train[5000:]

hist = model.fit(X_train_new,Y_train_new,epochs = 3, batch_size = 512,validation_data=(X_valid,Y_valid))

model.evaluate(X_test,Y_test)
